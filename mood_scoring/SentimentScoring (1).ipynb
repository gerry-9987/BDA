{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6190aecd",
   "metadata": {},
   "source": [
    "# About this notebook\n",
    "This notebook is meant to be called and ran by an eventbridge or lambda function to trigger the sentiment scoring for data from an s3 bucket. \n",
    "\n",
    "The sections first run through all the installations for sagemaker and other necessary libraries, then all the required imports.\n",
    "\n",
    "The next section calls a BERT-based model from Huggingface,[cardiffnlp/twitter-roberta-base-sentiment-latest](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment-latest) to create a function. This function, `rate_text(text)`, takes in argument `text<string>` and returns a `float` value where $-1<float<1$ to rate the sentiment of the text. \n",
    "\n",
    "The following section starts a connection with the s3 bucket and retrieves the data. It then converts it to a pandas df, then calls the function `rate_text()` on each row and stores the value in a new column called `df[mood_score]`\n",
    "\n",
    "The next section calls another BERT-based model from Huggingface, [j-hartmann/emotion-english-distilroberta-base](https://huggingface.co/j-hartmann/emotion-english-distilroberta-base) to create another function. This function, `sentiments(text)` returns an array of positive scores, where $0<score<1$, for 7 emotions, namely \n",
    "1. Anger\n",
    "2. Disgust\n",
    "3. Fear\n",
    "4. Joy\n",
    "5. Neutral\n",
    "6. Sadness\n",
    "7. Surprise\n",
    "meaning it returns an array of this shape:\n",
    "Output:\n",
    "`[[{'label': 'anger', 'score': 0.004419783595949411},\n",
    "  {'label': 'disgust', 'score': 0.0016119900392368436},\n",
    "  {'label': 'fear', 'score': 0.0004138521908316761},\n",
    "  {'label': 'joy', 'score': 0.9771687984466553},\n",
    "  {'label': 'neutral', 'score': 0.005764586851000786},\n",
    "  {'label': 'sadness', 'score': 0.002092392183840275},\n",
    "  {'label': 'surprise', 'score': 0.008528684265911579}]]`\n",
    "\n",
    "The last section calls this second model and adds the scores to 7 different columns in the df. The final df is then combined and written into a destination bucket as a new csv file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf76ff8",
   "metadata": {},
   "source": [
    "## Section 1: installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c31be60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: gensim in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gensim) (6.3.0)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gensim) (1.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from gensim) (1.22.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "22920f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: sagemaker>=2.48.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.143.0)\n",
      "Requirement already satisfied: importlib-metadata<5.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (4.13.0)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (1.0.1)\n",
      "Requirement already satisfied: protobuf3-to-dict<1.0,>=0.1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (0.1.5)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (0.2.0)\n",
      "Requirement already satisfied: PyYAML==5.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (5.4.1)\n",
      "Requirement already satisfied: boto3<2.0,>=1.26.28 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (1.26.71)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (0.3.0)\n",
      "Requirement already satisfied: attrs<23,>=20.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (22.2.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (1.5.2)\n",
      "Requirement already satisfied: protobuf<4.0,>=3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (3.20.3)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (0.7.5)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (3.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (21.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (1.22.3)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker>=2.48.0) (2.6.2)\n",
      "Requirement already satisfied: botocore<1.30.0,>=1.29.71 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker>=2.48.0) (1.29.71)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker>=2.48.0) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.26.28->sagemaker>=2.48.0) (1.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<5.0,>=1.4.0->sagemaker>=2.48.0) (3.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker>=2.48.0) (3.0.9)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from protobuf3-to-dict<1.0,>=0.1.5->sagemaker>=2.48.0) (1.16.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.48.0) (0.19.3)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker>=2.48.0) (65.6.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker>=2.48.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker>=2.48.0) (2022.7)\n",
      "Requirement already satisfied: dill>=0.3.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>=2.48.0) (0.3.6)\n",
      "Requirement already satisfied: ppft>=1.7.6.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>=2.48.0) (1.7.6.6)\n",
      "Requirement already satisfied: multiprocess>=0.70.14 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>=2.48.0) (0.70.14)\n",
      "Requirement already satisfied: pox>=0.3.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker>=2.48.0) (0.3.2)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from schema->sagemaker>=2.48.0) (21.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from botocore<1.30.0,>=1.29.71->boto3<2.0,>=1.26.28->sagemaker>=2.48.0) (1.26.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install \"sagemaker>=2.48.0\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "801b8e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.27.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.22.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (1.26.8)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.15.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\n",
      "Requirement already satisfied: cmake in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.26.1)\n",
      "Requirement already satisfied: lit in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.22.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install transformers\n",
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ceb7b14",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64b7ad48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoConfig\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "   \n",
    "import time\n",
    "import pandas as pd\n",
    "import io\n",
    "import re \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1908fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output will be stored in raw-data-is459-chatgpt-sentiments/write/\n",
      "\n",
      "IAM Role: arn:aws:iam::183972219153:role/service-role/AmazonSageMaker-ExecutionRole-20230329T165220\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "    session = sagemaker.Session()\n",
    "    bucket = \"raw-data-is459-chatgpt-sentiments\"\n",
    "    prefix = \"write/\"\n",
    "except ValueError:\n",
    "    iam = boto3.client('iam')\n",
    "    role = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "print(\"Output will be stored in {}/{}\".format(bucket, prefix))\n",
    "print(\"\\nIAM Role: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744e1c4",
   "metadata": {},
   "source": [
    "## Section 2: text rating (-1 to 1 numeric score for overall sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b740598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment-latest\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "config = AutoConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "tokenizer.model_max_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26dfd400",
   "metadata": {},
   "outputs": [],
   "source": [
    "###--- this function abstracts out the text processing. returns +ve, -ve or 0 for positive mood, negative, or neutral\n",
    "def rate_text(text):\n",
    "    \"\"\"\n",
    "    This function takes a text and puts it through the model we retrieved from huggingfaces. The model returns \n",
    "        positive: <float>\n",
    "        neutral: <float>\n",
    "        negative <float>\n",
    "    We want to find the one with the highest magnitude and represent it as a float from -1.00 to 1.00\n",
    "    \"\"\"\n",
    "    # sanitize the data\n",
    "    text=str(text)\n",
    "    if len(text)> 1200:\n",
    "        text=text[:1200]\n",
    "    text = preprocess(text)\n",
    "    \n",
    "    # call the huggingfaces model\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    \n",
    "    #extract the response and turn it into a float\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = config.id2label[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "    \n",
    "    winner=config.id2label[ranking[np.argmax(scores)]]\n",
    "    multiplier = 1 if winner==\"positive\" else 0 if winner==\"neutral\" else -1\n",
    "    print(multiplier * scores.max())\n",
    "    return multiplier * scores.max()\n",
    "\n",
    "def score_mood(df):\n",
    "    \"\"\"\n",
    "    This is a helper function to help pandas apply the above rate_text function more easily to a dataframe\n",
    "    \"\"\"\n",
    "    df[\"mood_score\"] = df[\"text\"].apply(rate_text)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9e106a",
   "metadata": {},
   "source": [
    "## Section 3: Reading from s3 bucket\n",
    "Currently this uses the 500 line test data under the intermediate folder on our project s3 bucket. Calling the model and modifying the test data takes 90s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4bb099f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = boto3.client('s3')\n",
    "bucket = \"raw-data-is459-chatgpt-sentiments\"\n",
    "subfolder = \"read\"\n",
    "bucket_contents = conn.list_objects(Bucket=bucket, Prefix=subfolder)['Contents']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327390fd",
   "metadata": {},
   "source": [
    "## Section 4: Sentiment scores\n",
    "This part modifies the df to append 7 more columns for 7 emotions: `['anger','disgust','fear','joy','neutral','sadness','surprise']`. Going through the test data takes 50s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "80c79487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\", return_all_scores=True)\n",
    "results=classifier(\"I love this!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f350de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_moods(df):\n",
    "    \"\"\"\n",
    "    This function calls the classifier on each row of a df\n",
    "    \"\"\"\n",
    "    for index, row in df.iterrows():\n",
    "        # Apply the classifier function to the \"text\" column\n",
    "        text=str(row[\"text\"])\n",
    "        if len(text)>1200:\n",
    "            text=text[:1200]\n",
    "        results = classifier(text)\n",
    "        results = results[0]\n",
    "        # store results in the df\n",
    "        for result in results:\n",
    "            df.loc[index, result[\"label\"]] = result[\"score\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc69e826",
   "metadata": {},
   "source": [
    "## Section 5: Writing to s3 and calling the pipeline functions\n",
    "We first take the csv from s3, then batch them, call the above functions in sequence, then write the dataframe as a csv again into another folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad943ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are for the main function to call to batch and write the results to s3\n",
    "\n",
    "def get_batch_name(idx):\n",
    "    return f'batch_{idx // 500}'\n",
    "\n",
    "def write_to_s3(df):\n",
    "    timestamp=str(time.time())\n",
    "    fname = f\"final_data_{timestamp}.csv\"\n",
    "    csv_buffer = df.to_csv(index=False)\n",
    "    s3_object = os.path.join(prefix, fname)\n",
    "    boto3.Session().resource(\"s3\").Bucket(bucket).Object(s3_object).put(Body=csv_buffer)\n",
    "\n",
    "    s3_train_data = \"s3://{}/{}\".format(bucket, s3_object)\n",
    "    print(\"Uploaded data to S3: {}\".format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78d8789f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read/\n",
      "read/reddit_ChatGPT_1680084943.csv\n",
      "read/reddit_ChatGPT_1680084943.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8354777693748474\n",
      "-0.5499265193939209\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512659.4417644.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680084943.csv\n",
      "read/reddit_ChatGPT_1680100961.csv\n",
      "read/reddit_ChatGPT_1680100961.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.8242226243019104\n",
      "-0.8727233409881592\n",
      "-0.662940263748169\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512661.786155.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680100961.csv\n",
      "read/reddit_ChatGPT_1680103686.csv\n",
      "read/reddit_ChatGPT_1680103686.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.690098226070404\n",
      "0.5132157206535339\n",
      "-0.8242226243019104\n",
      "-0.8727233409881592\n",
      "-0.662940263748169\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 5 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512665.7751522.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680103686.csv\n",
      "read/reddit_ChatGPT_1680106544.csv\n",
      "read/reddit_ChatGPT_1680106544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.5247394442558289\n",
      "-0.8895884156227112\n",
      "-0.690098226070404\n",
      "0.5132157206535339\n",
      "-0.8242226243019104\n",
      "-0.8727233409881592\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 6 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512670.6090207.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680106544.csv\n",
      "read/reddit_ChatGPT_1680117344.csv\n",
      "read/reddit_ChatGPT_1680117344.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.7438158392906189\n",
      "-0.6676225662231445\n",
      "-0.8494789600372314\n",
      "-0.5316864252090454\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512673.2383635.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680117344.csv\n",
      "read/reddit_ChatGPT_1680128144.csv\n",
      "read/reddit_ChatGPT_1680128144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6734338998794556\n",
      "-0.9173726439476013\n",
      "-0.6908273100852966\n",
      "0.6239805221557617\n",
      "-0.6171312928199768\n",
      "-0.802564799785614\n",
      "-0.7484875917434692\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 7 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512677.4832675.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680128144.csv\n",
      "read/reddit_ChatGPT_1680138944.csv\n",
      "read/reddit_ChatGPT_1680138944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.9326626062393188\n",
      "-0.7411770820617676\n",
      "0.6657037734985352\n",
      "-0.6984638571739197\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512680.229128.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680138944.csv\n",
      "read/reddit_ChatGPT_1680149744.csv\n",
      "read/reddit_ChatGPT_1680149744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.720626950263977\n",
      "0.8058609366416931\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512680.9944742.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680149744.csv\n",
      "read/reddit_ChatGPT_1680160544.csv\n",
      "read/reddit_ChatGPT_1680160544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.8889098167419434\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512682.4573312.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680160544.csv\n",
      "read/reddit_ChatGPT_1680182144.csv\n",
      "read/reddit_ChatGPT_1680182144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.663652241230011\n",
      "-0.6626660227775574\n",
      "-0.7595174908638\n",
      "-0.6023645997047424\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512685.8955016.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680182144.csv\n",
      "read/reddit_ChatGPT_1680192944.csv\n",
      "read/reddit_ChatGPT_1680192944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6527845859527588\n",
      "-0.7589578032493591\n",
      "0.6357905864715576\n",
      "-0.8843733072280884\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512687.9291975.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680192944.csv\n",
      "read/reddit_ChatGPT_1680203744.csv\n",
      "read/reddit_ChatGPT_1680203744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.5592645406723022\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512688.7087765.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680203744.csv\n",
      "read/reddit_ChatGPT_1680214544.csv\n",
      "read/reddit_ChatGPT_1680214544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.565837562084198\n",
      "0.599141538143158\n",
      "-0.6546907424926758\n",
      "-0.8244044780731201\n",
      "-0.8171092867851257\n",
      "0.8125463128089905\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 6 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512692.8532944.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680214544.csv\n",
      "read/reddit_ChatGPT_1680225344.csv\n",
      "read/reddit_ChatGPT_1680225344.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8869321942329407\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512693.4808023.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680225344.csv\n",
      "read/reddit_ChatGPT_1680236144.csv\n",
      "read/reddit_ChatGPT_1680236144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8023157715797424\n",
      "0.7565117478370667\n",
      "0.4427316188812256\n",
      "-0.8517107963562012\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512695.414779.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680236144.csv\n",
      "read/reddit_ChatGPT_1680246944.csv\n",
      "read/reddit_ChatGPT_1680246944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.7819551825523376\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512696.6113138.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680246944.csv\n",
      "read/reddit_ChatGPT_1680257744.csv\n",
      "read/reddit_ChatGPT_1680257744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.7098051309585571\n",
      "0.8709936738014221\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512698.8970695.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680257744.csv\n",
      "read/reddit_ChatGPT_1680268544.csv\n",
      "read/reddit_ChatGPT_1680268544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.8931945562362671\n",
      "0.7887241840362549\n",
      "0.7722839117050171\n",
      "-0.5326143503189087\n",
      "-0.671266496181488\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 5 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512702.2463107.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680268544.csv\n",
      "read/reddit_ChatGPT_1680279344.csv\n",
      "read/reddit_ChatGPT_1680279344.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8090875744819641\n",
      "-0.8907143473625183\n",
      "0.7746117115020752\n",
      "-0.5911434292793274\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512704.9580357.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680279344.csv\n",
      "read/reddit_ChatGPT_1680290144.csv\n",
      "read/reddit_ChatGPT_1680290144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.7105122804641724\n",
      "-0.9200248122215271\n",
      "-0.5472201704978943\n",
      "-0.9364428520202637\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512707.1405294.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680290144.csv\n",
      "read/reddit_ChatGPT_1680300944.csv\n",
      "read/reddit_ChatGPT_1680300944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.49744659662246704\n",
      "0.9239189028739929\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512708.5196488.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680300944.csv\n",
      "read/reddit_ChatGPT_1680311744.csv\n",
      "read/reddit_ChatGPT_1680311744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.849941074848175\n",
      "0.6714938879013062\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512710.7667758.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680311744.csv\n",
      "read/reddit_ChatGPT_1680322544.csv\n",
      "read/reddit_ChatGPT_1680322544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8303837180137634\n",
      "-0.7860839366912842\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512713.1103241.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680322544.csv\n",
      "read/reddit_ChatGPT_1680333344.csv\n",
      "read/reddit_ChatGPT_1680333344.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.7266636490821838\n",
      "-0.79803866147995\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512714.887077.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680333344.csv\n",
      "read/reddit_ChatGPT_1680354944.csv\n",
      "read/reddit_ChatGPT_1680354944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6174522638320923\n",
      "-0.6208103895187378\n",
      "-0.6792789697647095\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512717.9032278.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680354944.csv\n",
      "read/reddit_ChatGPT_1680365744.csv\n",
      "read/reddit_ChatGPT_1680365744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.5093553066253662\n",
      "-0.9417318105697632\n",
      "0.9498606324195862\n",
      "-0.5649804472923279\n",
      "-0.7456260323524475\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 5 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512720.3709455.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680365744.csv\n",
      "read/reddit_ChatGPT_1680376544.csv\n",
      "read/reddit_ChatGPT_1680376544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.4956660866737366\n",
      "-0.5753933787345886\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512721.5777042.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680376544.csv\n",
      "read/reddit_ChatGPT_1680398144.csv\n",
      "read/reddit_ChatGPT_1680398144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6290038228034973\n",
      "-0.7262994647026062\n",
      "-0.709962785243988\n",
      "-0.5366230607032776\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512724.2716312.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680398144.csv\n",
      "read/reddit_ChatGPT_1680408944.csv\n",
      "read/reddit_ChatGPT_1680408944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.5948002934455872\n",
      "0.6366904377937317\n",
      "-0.5107749104499817\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512726.517694.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680408944.csv\n",
      "read/reddit_ChatGPT_1680419744.csv\n",
      "read/reddit_ChatGPT_1680419744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.7628846168518066\n",
      "-0.6176762580871582\n",
      "-0.5718125700950623\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512729.1483371.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680419744.csv\n",
      "read/reddit_ChatGPT_1680421753.csv\n",
      "read/reddit_ChatGPT_1680421753.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8924930095672607\n",
      "0.8486494421958923\n",
      "0.7628846168518066\n",
      "-0.6176762580871582\n",
      "-0.5718125700950623\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 5 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512732.2137039.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680421753.csv\n",
      "read/reddit_ChatGPT_1680423800.csv\n",
      "read/reddit_ChatGPT_1680423800.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8924930095672607\n",
      "0.8486494421958923\n",
      "0.7628846168518066\n",
      "-0.6176762580871582\n",
      "-0.5718125700950623\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 5 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512735.2069614.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680423800.csv\n",
      "read/reddit_ChatGPT_1680430544.csv\n",
      "read/reddit_ChatGPT_1680430544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8121212720870972\n",
      "-0.6502472162246704\n",
      "0.8924930095672607\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512737.4333231.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680430544.csv\n",
      "read/reddit_ChatGPT_1680441344.csv\n",
      "read/reddit_ChatGPT_1680441344.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.5959388613700867\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512739.2927122.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680441344.csv\n",
      "read/reddit_ChatGPT_1680452144.csv\n",
      "read/reddit_ChatGPT_1680452144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.7031922340393066\n",
      "0.7889723181724548\n",
      "0.7095482349395752\n",
      "-0.8521877527236938\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512741.4981647.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680452144.csv\n",
      "read/reddit_ChatGPT_1680462944.csv\n",
      "read/reddit_ChatGPT_1680462944.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.4907047152519226\n",
      "-0.5945173501968384\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 2 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512743.217658.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680462944.csv\n",
      "read/reddit_ChatGPT_1680473744.csv\n",
      "read/reddit_ChatGPT_1680473744.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.820102334022522\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512743.7916558.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680473744.csv\n",
      "read/reddit_ChatGPT_1680484544.csv\n",
      "read/reddit_ChatGPT_1680484544.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.7274003028869629\n",
      "-0.8718374371528625\n",
      "0.7628228664398193\n",
      "-0.5073608160018921\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 4 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512746.2171888.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680484544.csv\n",
      "read/reddit_ChatGPT_1680495344.csv\n",
      "read/reddit_ChatGPT_1680495344.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.9141363501548767\n",
      "-0.6994962692260742\n",
      "-0.5416537523269653\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512748.1904109.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680495344.csv\n",
      "read/reddit_ChatGPT_1680506144.csv\n",
      "read/reddit_ChatGPT_1680506144.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.4918779730796814\n",
      "0.8976161479949951\n",
      "-0.7684381604194641\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 3 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512750.2623696.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_ChatGPT_1680506144.csv\n",
      "read/reddit_Professors_1680182146.csv\n",
      "read/reddit_Professors_1680182146.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6282377243041992\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512751.1674795.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_Professors_1680182146.csv\n",
      "read/reddit_Professors_1680398146.csv\n",
      "read/reddit_Professors_1680398146.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.543781042098999\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512753.0585337.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_Professors_1680398146.csv\n",
      "read/reddit_Professors_1680484546.csv\n",
      "read/reddit_Professors_1680484546.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.5234524011611938\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512754.2123873.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_Professors_1680484546.csv\n",
      "read/reddit_Teachers_1680128147.csv\n",
      "read/reddit_Teachers_1680128147.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6715918779373169\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512755.2687268.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_Teachers_1680128147.csv\n",
      "read/reddit_Teachers_1680225346.csv\n",
      "read/reddit_Teachers_1680225346.csv\n",
      "----- batching\n",
      "---- looping\n",
      "0.8912794589996338\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 1 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512755.7533648.csv\n",
      "====Batch done=====\n",
      "----deleted read/reddit_Teachers_1680225346.csv\n",
      "read/twitter_1680419746.csv\n",
      "read/twitter_1680419746.csv\n",
      "----- batching\n",
      "---- looping\n",
      "-0.6051859855651855\n",
      "-0.6313095688819885\n",
      "0.8819791674613953\n",
      "-0.8116339445114136\n",
      "-0.5280680060386658\n",
      "0.7507266402244568\n",
      "0.912634551525116\n",
      "-0.9601984620094299\n",
      "-0.46447983384132385\n",
      "0.9306484460830688\n",
      "0.8992787599563599\n",
      "0.9481680989265442\n",
      "0.938081681728363\n",
      "-0.5094154477119446\n",
      "0.9370185732841492\n",
      "0.9353464841842651\n",
      "-0.6799706816673279\n",
      "-0.8014495968818665\n",
      "0.8833019137382507\n",
      "-0.6868806481361389\n",
      "-0.9063767194747925\n",
      "0.8219571113586426\n",
      "-0.972934901714325\n",
      "-0.8946813344955444\n",
      "-0.8908833265304565\n",
      "0.7307391166687012\n",
      "-0.9645928740501404\n",
      "-0.6863217949867249\n",
      "0.7479814887046814\n",
      "0.9326666593551636\n",
      "0.9236782789230347\n",
      "-0.8663393259048462\n",
      "0.9125422239303589\n",
      "0.9011608362197876\n",
      "-0.7819220423698425\n",
      "-0.7337594628334045\n",
      "-0.6376954317092896\n",
      "-0.6082547307014465\n",
      "0.6513257026672363\n",
      "-0.514216423034668\n",
      "0.6191821694374084\n",
      "-0.9418424367904663\n",
      "0.7696641683578491\n",
      "0.5372142195701599\n",
      "-0.9145383238792419\n",
      "0.6248948574066162\n",
      "0.5006768703460693\n",
      "-0.8951053619384766\n",
      "-0.6790982484817505\n",
      "-0.9526230692863464\n",
      "-0.8957169651985168\n",
      "-0.5606604218482971\n",
      "0.9160845279693604\n",
      "0.5910035371780396\n",
      "-0.9326574206352234\n",
      "0.9402766823768616\n",
      "0.7879140377044678\n",
      "0.637527585029602\n",
      "0.916764497756958\n",
      "-0.5085971355438232\n",
      "-0.6163467168807983\n",
      "0.5310357213020325\n",
      "-0.5917088389396667\n",
      "0.923035740852356\n",
      "0.9102234244346619\n",
      "-0.8831695318222046\n",
      "0.5680109858512878\n",
      "-0.87778639793396\n",
      "-0.6646300554275513\n",
      "-0.6004358530044556\n",
      "0.8342409133911133\n",
      "-0.5574710369110107\n",
      "0.7588257789611816\n",
      "-0.9319628477096558\n",
      "-0.7562162280082703\n",
      "0.9167045950889587\n",
      "-0.6611666083335876\n",
      "-0.5079323649406433\n",
      "-0.6706202626228333\n",
      "-0.9857757091522217\n",
      "-0.7592776417732239\n",
      "-0.9235408902168274\n",
      "-0.5715067386627197\n",
      "0.6200090050697327\n",
      "-0.8349988460540771\n",
      "-0.5169973373413086\n",
      "-0.5457143187522888\n",
      "0.941445529460907\n",
      "-0.6384723782539368\n",
      "-0.5923339128494263\n",
      "-0.9452664256095886\n",
      "-0.7501785755157471\n",
      "-0.8788104057312012\n",
      "0.6599355340003967\n",
      "0.8901501893997192\n",
      "-0.5771417021751404\n",
      "-0.5062915682792664\n",
      "-0.8498595952987671\n",
      "-0.7112047672271729\n",
      "-0.8397571444511414\n",
      "0.8952680826187134\n",
      "-0.9563489556312561\n",
      "0.7339492440223694\n",
      "-0.5543916821479797\n",
      "-0.7216612100601196\n",
      "0.6456502079963684\n",
      "-0.5099620223045349\n",
      "-0.6993340253829956\n",
      "-0.8545069098472595\n",
      "-0.4794839322566986\n",
      "0.786539614200592\n",
      "-0.9424365758895874\n",
      "-0.6542966365814209\n",
      "0.8909783363342285\n",
      "0.8156961798667908\n",
      "0.827038049697876\n",
      "0.5024144649505615\n",
      "0.8704071640968323\n",
      "0.9055349826812744\n",
      "0.49365824460983276\n",
      "-0.845476508140564\n",
      "-0.5563311576843262\n",
      "0.9094029068946838\n",
      "-0.608339786529541\n",
      "-0.8175904750823975\n",
      "0.8139375448226929\n",
      "0.74837726354599\n",
      "0.945586621761322\n",
      "-0.48282814025878906\n",
      "0.8825029730796814\n",
      "-0.8377344608306885\n",
      "0.7648985385894775\n",
      "-0.5002421736717224\n",
      "0.9027220606803894\n",
      "-0.7782116532325745\n",
      "0.9054157137870789\n",
      "0.926331102848053\n",
      "-0.9750144481658936\n",
      "-0.7439635396003723\n",
      "0.8692405223846436\n",
      "0.8984060883522034\n",
      "-0.9288559556007385\n",
      "-0.8690710067749023\n",
      "-0.9265071749687195\n",
      "-0.6671159267425537\n",
      "-0.7036914825439453\n",
      "0.8741092681884766\n",
      "-0.9452177286148071\n",
      "-0.9772334098815918\n",
      "-0.5654577612876892\n",
      "-0.873340368270874\n",
      "-0.7875108122825623\n",
      "-0.8120738863945007\n",
      "-0.8385421633720398\n",
      "0.8521313667297363\n",
      "-0.5747050046920776\n",
      "0.8924977779388428\n",
      "0.8684806823730469\n",
      "-0.7396903038024902\n",
      "0.888767421245575\n",
      "-0.9095582365989685\n",
      "-0.8723477721214294\n",
      "-0.8671082258224487\n",
      "-0.7876280546188354\n",
      "-0.7042048573493958\n",
      "-0.9265627264976501\n",
      "-0.616798460483551\n",
      "-0.6471851468086243\n",
      "-0.9417231678962708\n",
      "0.6473459601402283\n",
      "0.8168027400970459\n",
      "-0.6475360989570618\n",
      "-0.6093425750732422\n",
      "-0.6196669340133667\n",
      "-0.61802738904953\n",
      "-0.5507277250289917\n",
      "0.9437198638916016\n",
      "-0.6353694200515747\n",
      "0.9258286952972412\n",
      "-0.9624122977256775\n",
      "0.9229328036308289\n",
      "-0.722934365272522\n",
      "-0.5773303508758545\n",
      "-0.9897328019142151\n",
      "-0.6724991798400879\n",
      "0.8896123170852661\n",
      "0.9404027462005615\n",
      "-0.7947794795036316\n",
      "0.5811125636100769\n",
      "0.9060664772987366\n",
      "-0.8898343443870544\n",
      "0.9209978580474854\n",
      "-0.7555940747261047\n",
      "-0.6038916110992432\n",
      "0.8225283622741699\n",
      "-0.9031098484992981\n",
      "-0.37351900339126587\n",
      "0.5456680655479431\n",
      "0.7583981156349182\n",
      "-0.7701707482337952\n",
      "-0.9369528293609619\n",
      "-0.8816829919815063\n",
      "0.9347901940345764\n",
      "-0.8725216388702393\n",
      "-0.943514347076416\n",
      "-0.9815424084663391\n",
      "-0.5046525597572327\n",
      "-0.9849581718444824\n",
      "0.5202524065971375\n",
      "-0.8808943629264832\n",
      "0.5512698888778687\n",
      "-0.893803596496582\n",
      "-0.9374828934669495\n",
      "-0.5318396687507629\n",
      "0.7515115737915039\n",
      "-0.5011815428733826\n",
      "-0.953096330165863\n",
      "0.8765628933906555\n",
      "-0.7718309164047241\n",
      "0.8268499970436096\n",
      "-0.4970278739929199\n",
      "-0.643119752407074\n",
      "-0.9261131882667542\n",
      "-0.8308120369911194\n",
      "0.5380776524543762\n",
      "-0.8347366452217102\n",
      "-0.6163544654846191\n",
      "0.522267758846283\n",
      "-0.615481972694397\n",
      "-0.7564294338226318\n",
      "0.8992511630058289\n",
      "-0.9756222367286682\n",
      "0.8038828372955322\n",
      "-0.8105143308639526\n",
      "0.9333040714263916\n",
      "-0.5677415132522583\n",
      "-0.6476488709449768\n",
      "0.6360819339752197\n",
      "-0.8160080909729004\n",
      "-0.5183668732643127\n",
      "-0.7218527793884277\n",
      "0.550838053226471\n",
      "0.9377602934837341\n",
      "0.8886735439300537\n",
      "-0.7577045559883118\n",
      "-0.9818122982978821\n",
      "-0.8872920274734497\n",
      "-0.8337732553482056\n",
      "-0.41581815481185913\n",
      "-0.6764834523200989\n",
      "-0.8865267038345337\n",
      "0.7889757752418518\n",
      "-0.9823587536811829\n",
      "-0.8503908514976501\n",
      "-0.5824885368347168\n",
      "-0.9685027599334717\n",
      "0.8955848813056946\n",
      "-0.9725934863090515\n",
      "0.6308144330978394\n",
      "-0.8814482092857361\n",
      "-0.6277706027030945\n",
      "0.9607535004615784\n",
      "-0.7112926840782166\n",
      "-0.642333984375\n",
      "-0.8295683860778809\n",
      "0.7075966596603394\n",
      "-0.9705983400344849\n",
      "-0.9545459747314453\n",
      "-0.7393114566802979\n",
      "-0.5652203559875488\n",
      "0.9466326832771301\n",
      "0.7211231589317322\n",
      "-0.8927621245384216\n",
      "-0.8469316959381104\n",
      "-0.9289529919624329\n",
      "0.44030874967575073\n",
      "-0.9472852945327759\n",
      "0.9245330095291138\n",
      "-0.9048216938972473\n",
      "-0.883614718914032\n",
      "-0.5978071093559265\n",
      "0.6764928102493286\n",
      "-0.9868384003639221\n",
      "0.9259870052337646\n",
      "-0.914242148399353\n",
      "0.951134204864502\n",
      "0.9064904451370239\n",
      "-0.9078447222709656\n",
      "0.8212466239929199\n",
      "0.9157562851905823\n",
      "0.809074878692627\n",
      "-0.7255464196205139\n",
      "-0.5119053721427917\n",
      "0.6976274847984314\n",
      "0.8827648162841797\n",
      "0.799206018447876\n",
      "-0.7928640842437744\n",
      "-0.6349620819091797\n",
      "0.8035308122634888\n",
      "-0.8200197815895081\n",
      "-0.6890113353729248\n",
      "0.8067545294761658\n",
      "-0.5208405256271362\n",
      "-0.6652665734291077\n",
      "0.9359774589538574\n",
      "0.8833438754081726\n",
      "0.7793875336647034\n",
      "-0.9038044810295105\n",
      "-0.8011054992675781\n",
      "0.9373235702514648\n",
      "-0.8694888949394226\n",
      "0.8673053979873657\n",
      "-0.9300647377967834\n",
      "0.504601240158081\n",
      "-0.752065122127533\n",
      "-0.5702269077301025\n",
      "0.8554714322090149\n",
      "0.6510773301124573\n",
      "-0.7139564156532288\n",
      "0.6704298257827759\n",
      "0.8546520471572876\n",
      "-0.8250152468681335\n",
      "0.5244185924530029\n",
      "0.8375847339630127\n",
      "-0.7833764553070068\n",
      "-0.5839532613754272\n",
      "0.9286788105964661\n",
      "0.7900920510292053\n",
      "-0.8785343766212463\n",
      "0.5384450554847717\n",
      "-0.5022637248039246\n",
      "0.9586476683616638\n",
      "-0.9106412529945374\n",
      "-0.9386986494064331\n",
      "-0.6215022802352905\n",
      "-0.7979656457901001\n",
      "-0.7999000549316406\n",
      "0.5192620754241943\n",
      "0.692499041557312\n",
      "0.7176437973976135\n",
      "-0.8569319248199463\n",
      "0.7774162888526917\n",
      "0.5930947661399841\n",
      "-0.9841707348823547\n",
      "-0.5453014373779297\n",
      "0.9164910912513733\n",
      "-0.765306293964386\n",
      "0.9205211400985718\n",
      "0.8611614108085632\n",
      "-0.6375986933708191\n",
      "-0.9380123615264893\n",
      "-0.9856501221656799\n",
      "0.78223717212677\n",
      "-0.8350679278373718\n",
      "-0.5020411610603333\n",
      "0.9027650952339172\n",
      "0.6624644994735718\n",
      "-0.6689771413803101\n",
      "0.6634155511856079\n",
      "0.8709849119186401\n",
      "-0.7086420655250549\n",
      "-0.9111831188201904\n",
      "0.7452425360679626\n",
      "-0.7231358289718628\n",
      "-0.5445382595062256\n",
      "0.712896466255188\n",
      "-0.7075338959693909\n",
      "0.919562816619873\n",
      "-0.899864912033081\n",
      "-0.7433462738990784\n",
      "0.9179295897483826\n",
      "0.4958920478820801\n",
      "-0.9645469784736633\n",
      "-0.6473377346992493\n",
      "0.714611828327179\n",
      "-0.8768909573554993\n",
      "0.8026079535484314\n",
      "-0.7533144354820251\n",
      "-0.7524533867835999\n",
      "-0.8140937685966492\n",
      "0.9371165037155151\n",
      "0.8496939539909363\n",
      "0.866019070148468\n",
      "0.7879467606544495\n",
      "-0.6477928757667542\n",
      "0.6197293400764465\n",
      "0.9508004188537598\n",
      "-0.6860054731369019\n",
      "0.8960217833518982\n",
      "-0.9850220084190369\n",
      "-0.5660916566848755\n",
      "0.9507058262825012\n",
      "0.9473009705543518\n",
      "-0.6426239013671875\n",
      "0.8815191984176636\n",
      "-0.6450321674346924\n",
      "0.7486164569854736\n",
      "-0.9804500341415405\n",
      "0.813768744468689\n",
      "-0.6430541276931763\n",
      "0.5415880084037781\n",
      "-0.716286301612854\n",
      "0.8652824759483337\n",
      "-0.9184871912002563\n",
      "-0.7428799271583557\n",
      "-0.9368942379951477\n",
      "0.9090661406517029\n",
      "-0.9167169332504272\n",
      "0.6321374177932739\n",
      "0.8846297860145569\n",
      "0.8712311387062073\n",
      "0.8600452542304993\n",
      "0.6032995581626892\n",
      "0.8897528648376465\n",
      "0.7424437999725342\n",
      "0.9351248145103455\n",
      "0.9092976450920105\n",
      "0.5445137619972229\n",
      "-0.8754022717475891\n",
      "0.8640560507774353\n",
      "-0.9641727805137634\n",
      "-0.9320038557052612\n",
      "-0.8670471906661987\n",
      "-0.9663856029510498\n",
      "-0.9674320220947266\n",
      "-0.9372982978820801\n",
      "-0.828406810760498\n",
      "0.7481058239936829\n",
      "0.5116244554519653\n",
      "-0.8526643514633179\n",
      "0.7908464074134827\n",
      "-0.5429121851921082\n",
      "0.7258948683738708\n",
      "-0.9396777153015137\n",
      "0.8970257639884949\n",
      "0.885185182094574\n",
      "0.8982561230659485\n",
      "-0.5008030533790588\n",
      "-0.8145920038223267\n",
      "-0.9075640439987183\n",
      "-0.7161974906921387\n",
      "0.7798176407814026\n",
      "-0.941614031791687\n",
      "-0.7883166074752808\n",
      "-0.5603492259979248\n",
      "0.9117559790611267\n",
      "-0.6026024222373962\n",
      "-0.6704203486442566\n",
      "0.499514102935791\n",
      "-0.8216904401779175\n",
      "-0.8338568806648254\n",
      "0.934117317199707\n",
      "-0.673306941986084\n",
      "-0.5032650232315063\n",
      "0.6020021438598633\n",
      "-0.9594528079032898\n",
      "-0.6489729881286621\n",
      "0.636025607585907\n",
      "-0.6165702939033508\n",
      "0.8933157324790955\n",
      "0.8526024222373962\n",
      "-0.5762678384780884\n",
      "-0.95372074842453\n",
      "0.7671458125114441\n",
      "0.7223600149154663\n",
      "-0.6581565737724304\n",
      "0.7318524122238159\n",
      "0.5937895178794861\n",
      "-0.9470550417900085\n",
      "-0.79621422290802\n",
      "-0.775874674320221\n",
      "0.8477132320404053\n",
      "-0.852856457233429\n",
      "-0.8196849226951599\n",
      "0.9175248146057129\n",
      "-0.7218678593635559\n",
      "-0.8221427202224731\n",
      "0.8766916394233704\n",
      "0.738164484500885\n",
      "-0.6069953441619873\n",
      "-0.5524550676345825\n",
      "0.557727575302124\n",
      "-0.4463909864425659\n",
      "-0.9581795334815979\n",
      "0.7986223101615906\n",
      "-0.7418668866157532\n",
      "0.7090111970901489\n",
      "0.5647795796394348\n",
      "-0.5216089487075806\n",
      "0.7643628716468811\n",
      "0.8574324250221252\n",
      "-0.5241837501525879\n",
      "-0.6943117380142212\n",
      "-0.9444788694381714\n",
      "-0.861385703086853\n",
      "0.8443143963813782\n",
      "0.6082299947738647\n",
      "0.6294376850128174\n",
      "-0.984582781791687\n",
      "-0.6294121742248535\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 500 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512885.159504.csv\n",
      "====Batch done=====\n",
      "-0.8528401255607605\n",
      "-0.6862655282020569\n",
      "-0.6420665383338928\n",
      "-0.7536036968231201\n",
      "-0.980073869228363\n",
      "-0.8581082820892334\n",
      "0.8046342134475708\n",
      "-0.6902689933776855\n",
      "0.8194860219955444\n",
      "0.7678152322769165\n",
      "0.8646367192268372\n",
      "0.8684828281402588\n",
      "-0.5985900163650513\n",
      "0.9052280187606812\n",
      "-0.9204923510551453\n",
      "0.9549531936645508\n",
      "0.8859384059906006\n",
      "0.6922114491462708\n",
      "-0.7477102875709534\n",
      "-0.6076184511184692\n",
      "-0.5316356420516968\n",
      "-0.4578329622745514\n",
      "0.5419734120368958\n",
      "0.912632942199707\n",
      "-0.9161504507064819\n",
      "0.8827844262123108\n",
      "-0.9418685436248779\n",
      "0.7248960733413696\n",
      "0.9168710112571716\n",
      "-0.7001803517341614\n",
      "0.6039727926254272\n",
      "0.8546494841575623\n",
      "0.5054349303245544\n",
      "-0.7924814820289612\n",
      "0.550738513469696\n",
      "0.9096139669418335\n",
      "-0.5962077975273132\n",
      "-0.6146919131278992\n",
      "0.7105751037597656\n",
      "-0.792573094367981\n",
      "-0.9661111831665039\n",
      "0.7226231098175049\n",
      "0.573009729385376\n",
      "-0.9097772240638733\n",
      "-0.49392151832580566\n",
      "-0.7216067910194397\n",
      "-0.9020420908927917\n",
      "0.8363015651702881\n",
      "0.9052410125732422\n",
      "-0.9169130921363831\n",
      "===sentiment scored===\n",
      "===moods added===\n",
      "This batch_df is 50 long\n",
      "---writing to s3----\n",
      "Uploaded data to S3: s3://raw-data-is459-chatgpt-sentiments/write/final_data_1680512900.94896.csv\n",
      "====Batch done=====\n",
      "----deleted read/twitter_1680419746.csv\n",
      "----success,  all done----\n"
     ]
    }
   ],
   "source": [
    "def main(df):\n",
    "    print(\"----- batching\")\n",
    "    batched_df = df.groupby(get_batch_name, sort=False)\n",
    "    print(\"---- looping\")            \n",
    "    batch_no=0\n",
    "    finished_batches=0\n",
    "    for batch_name, batch_df in batched_df:\n",
    "        batch_no+=1\n",
    "        if batch_no<=finished_batches:\n",
    "            batch_no+=1\n",
    "        else:\n",
    "            batch_df = score_mood(batch_df)\n",
    "            print(\"===sentiment scored===\")\n",
    "            # Initialise the columns\n",
    "            sentiments = ['anger','disgust','fear','joy','neutral','sadness','surprise']\n",
    "            for sentiment in sentiments:\n",
    "                batch_df[sentiment] = 0.0\n",
    "            batch_df=update_moods(batch_df)\n",
    "            print(\"===moods added===\")\n",
    "            print(f\"This batch_df is {len(batch_df)} long\")\n",
    "            print(\"---writing to s3----\")\n",
    "            write_to_s3(batch_df)\n",
    "            print(\"====Batch done=====\")\n",
    "            \n",
    "        \n",
    "def call_segment(df,file_path):\n",
    "    print(file_path)\n",
    "    s3 = boto3.resource('s3')\n",
    "    main(df)\n",
    "    timestamp=str(time.time())\n",
    "    # delete the original file from the source path\n",
    "    s3.Object(bucket_name=bucket, key=file_path).delete()\n",
    "    print(f\"----deleted {file_path}\")\n",
    "\n",
    "df = pd.DataFrame();\n",
    "# print(contents)\n",
    "for f in bucket_contents:\n",
    "    file_path=f['Key']\n",
    "    print(file_path)\n",
    "#     if \"cleaned_twitter.csv\" in file_path: # i will use cleaned_twitter first, all dataset needs to be in the same format\n",
    "    if not(file_path==subfolder+\"/\"):\n",
    "        obj = conn.get_object(Bucket=bucket, Key=f\"{file_path}\")\n",
    "        contents = obj['Body'].read().decode('utf-8')\n",
    "        data = pd.read_csv(io.StringIO(contents))\n",
    "        df = pd.concat([data], axis=0)\n",
    "        call_segment(df,file_path)\n",
    "print(\"----success,  all done----\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c5bb5",
   "metadata": {},
   "source": [
    "# Citations\n",
    "\n",
    "## Hartmann's emotion DistilRoBERTa model\n",
    "```\n",
    "@misc{hartmann2022emotionenglish,\n",
    "  author={Hartmann, Jochen},\n",
    "  title={Emotion English DistilRoBERTa-base},\n",
    "  year={2022},\n",
    "  howpublished = {\\url{https://huggingface.co/j-hartmann/emotion-english-distilroberta-base/}},\n",
    "}\n",
    "```\n",
    "\n",
    "## Loureiro et. al.'s Twitter RoBERTa model\n",
    "```\n",
    "@inproceedings{loureiro-etal-2022-timelms,\n",
    "    title = \"{T}ime{LM}s: Diachronic Language Models from {T}witter\",\n",
    "    author = \"Loureiro, Daniel  and\n",
    "      Barbieri, Francesco  and\n",
    "      Neves, Leonardo  and\n",
    "      Espinosa Anke, Luis  and\n",
    "      Camacho-collados, Jose\",\n",
    "    booktitle = \"Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations\",\n",
    "    month = may,\n",
    "    year = \"2022\",\n",
    "    address = \"Dublin, Ireland\",\n",
    "    publisher = \"Association for Computational Linguistics\",\n",
    "    url = \"https://aclanthology.org/2022.acl-demo.25\",\n",
    "    doi = \"10.18653/v1/2022.acl-demo.25\",\n",
    "    pages = \"251--260\"\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
