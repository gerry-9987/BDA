{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/gerry/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/gerry/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /Users/gerry/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/gerry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import html\n",
    "from unicodedata import normalize\n",
    "\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import sys\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.parse.malt import MaltParser\n",
    "from nltk.corpus import words\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(\"../chatgpt-reddit-comments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iztdxuh</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>I've been shocked for days now, I don't need c...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iztn0q0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>\\n\\nI am so angry right now. I just wasted my...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>izudrph</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>iztfhtb</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>Worked on me, ngl.</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>izu2as9</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>Certified 10/10, must-see moment. It really di...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>16668</td>\n",
       "      <td>j5m0v6m</td>\n",
       "      <td>t3_10jmvpj</td>\n",
       "      <td>Read the T.O.S., you'll thank me later</td>\n",
       "      <td>r/technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>16669</td>\n",
       "      <td>j5m6aj0</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>What am I missing here... https://openai.com/t...</td>\n",
       "      <td>r/technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>16670</td>\n",
       "      <td>j5nylax</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>What does ChatGTP think of its own TOS?</td>\n",
       "      <td>r/technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>16671</td>\n",
       "      <td>j5mwpdr</td>\n",
       "      <td>t1_j5m6aj0</td>\n",
       "      <td>Don't know what they're referring to in the TO...</td>\n",
       "      <td>r/technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52415</th>\n",
       "      <td>\u001a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52416 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 comment_id comment_parent_id  \\\n",
       "0              0    iztdxuh         t3_zj2aeu   \n",
       "1              1    iztn0q0         t3_zj2aeu   \n",
       "2              2    izudrph         t3_zj2aeu   \n",
       "3              3    iztfhtb         t3_zj2aeu   \n",
       "4              4    izu2as9         t3_zj2aeu   \n",
       "...          ...        ...               ...   \n",
       "52411      16668    j5m0v6m        t3_10jmvpj   \n",
       "52412      16669    j5m6aj0        t1_j5m0v6m   \n",
       "52413      16670    j5nylax        t1_j5m0v6m   \n",
       "52414      16671    j5mwpdr        t1_j5m6aj0   \n",
       "52415          \u001a        NaN               NaN   \n",
       "\n",
       "                                            comment_body     subreddit  \n",
       "0      I've been shocked for days now, I don't need c...     r/ChatGPT  \n",
       "1       \\n\\nI am so angry right now. I just wasted my...     r/ChatGPT  \n",
       "2      chatgpt karma whoring is here folks! just when...     r/ChatGPT  \n",
       "3                                     Worked on me, ngl.     r/ChatGPT  \n",
       "4      Certified 10/10, must-see moment. It really di...     r/ChatGPT  \n",
       "...                                                  ...           ...  \n",
       "52411             Read the T.O.S., you'll thank me later  r/technology  \n",
       "52412  What am I missing here... https://openai.com/t...  r/technology  \n",
       "52413            What does ChatGTP think of its own TOS?  r/technology  \n",
       "52414  Don't know what they're referring to in the TO...  r/technology  \n",
       "52415                                                NaN           NaN  \n",
       "\n",
       "[52416 rows x 5 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_words_list = [\"class\", \"lecture\", \"professor\", \"prof\", \"homework\", \"hw\", \"exam\", \"examinations\", \"assignment\", \n",
    "\"study\", \"degree\", \"gpa\", \"cap\", \"scholarship\", \"scholar\", \"research\", \"thesis\", \"lab\", \"campus\", \"graduation\", \"grad\", \"syllabus\",\n",
    "\"textbook\", \"textbooks\", \"student\", \"students\", \"academic\", \"acad\", \"acads\", \"registrar\", \"tuition\", \"coursework\", \"course\", \"attendance\",\n",
    "\"faculty\", \"teacher\", \"teach\", \"learn\", \"internship\", \"intern\", \"library\", \"peer\", \"peers\", \"school\", \"schools\", \"university\", \"uni\", \"college\", \"colleges\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code references:\n",
    "    https://pythonguides.com/remove-unicode-characters-in-python/\n",
    "    https://www.kite.com/python/answers/how-to-decode-html-entities-in-python\n",
    "\"\"\"\n",
    "def decode_text(text):\n",
    "    # remove non-ASCII characters in string\n",
    "    decoded_text = text.encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # decode HTML entities\n",
    "    decoded_html = html.unescape(decoded_text)\n",
    "    return ''.join([word for word in decoded_html if word.isprintable()])\n",
    "\n",
    "\"\"\"\n",
    "Code reference:\n",
    "    https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python\n",
    "\"\"\"\n",
    "def remove_links(text):\n",
    "    return re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "\"\"\"\n",
    "Code reference:\n",
    "    https://catriscode.com/2021/03/02/extracting-or-removing-mentions-and-hashtags-in-tweets-using-python/\n",
    "\"\"\"\n",
    "def remove_mentions(text):\n",
    "    return re.sub(\"@[A-Za-z0-9_]+\",\"\", text)\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    return re.sub(\"#[A-Za-z0-9_]+\",\"\", text)\n",
    "\n",
    "def remove_stopwords(words_list):\n",
    "    stop_list = stopwords.words(\"english\")\n",
    "    stop_list.append(\"filler\")\n",
    "    return [word for word in words_list if word not in stop_list]\n",
    "\n",
    "def pos_to_wordnet(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_words(word_list):\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    # POS (part-of-speech) tagging\n",
    "    # nltk_tagged -> a list of tuples (word, pos tag)\n",
    "    nltk_tagged = nltk.pos_tag(word_list)\n",
    "\n",
    "    # returns a list of tuples of words and their wordnet_tag (after conversion from NLTK tag)\n",
    "    wordnet_tagged = list(map(lambda x: (x[0], pos_to_wordnet(x[1])), nltk_tagged))\n",
    "\n",
    "    # lemmatizing\n",
    "    lemmatized_words = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is not None:\n",
    "            # need POS tag as 2nd argument as it helps lemmatize the words more accurately\n",
    "            lemmatized_words.append(lemmatizer.lemmatize(word, tag))\n",
    "        elif tag in [wordnet.NOUN]:\n",
    "            lemmatized_words.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized_words\n",
    "\n",
    "def clean_original_text(text):\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    clean_list = []\n",
    "    sentence_list = nltk.sent_tokenize(text)\n",
    "    for sentence in sentence_list:\n",
    "        decoded_sentence = decode_text(sentence)\n",
    "        linkless_sentence = remove_links(decoded_sentence)\n",
    "        mentionless_sentence = remove_mentions(linkless_sentence)\n",
    "        tagless_sentence = remove_hashtags(mentionless_sentence)\n",
    "        words_list = nltk.RegexpTokenizer(r'\\w+').tokenize(tagless_sentence)\n",
    "        lemmatized_words = lemmatize_words(words_list)\n",
    "        useful_words = remove_stopwords(lemmatized_words)\n",
    "\n",
    "        if len(useful_words) > 0:\n",
    "            clean_list.extend(useful_words)\n",
    "    clean_text = ' '.join(clean_list)\n",
    "\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df[\"clean_text\"] = reddit_df[\"comment_body\"].apply(clean_original_text)\n",
    "reddit_df[\"clean_tokens\"] = reddit_df[\"clean_text\"].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df.drop_duplicates(subset=[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iztdxuh</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>I've been shocked for days now, I don't need c...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>shock day need clickbait</td>\n",
       "      <td>[shock, day, need, clickbait]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iztn0q0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>\\n\\nI am so angry right now. I just wasted my...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>[angry, right, waste, time, read, post, sub, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>izudrph</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>chatgpt karma whoring folk think stream though...</td>\n",
       "      <td>[chatgpt, karma, whoring, folk, think, stream,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>iztfhtb</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>Worked on me, ngl.</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>work ngl</td>\n",
       "      <td>[work, ngl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>izu2as9</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>Certified 10/10, must-see moment. It really di...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>certify see moment really shock core</td>\n",
       "      <td>[certify, see, moment, really, shock, core]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>16668</td>\n",
       "      <td>j5m0v6m</td>\n",
       "      <td>t3_10jmvpj</td>\n",
       "      <td>Read the T.O.S., you'll thank me later</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>read thank later</td>\n",
       "      <td>[read, thank, later]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>16669</td>\n",
       "      <td>j5m6aj0</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>What am I missing here... https://openai.com/t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>missing</td>\n",
       "      <td>[missing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>16670</td>\n",
       "      <td>j5nylax</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>What does ChatGTP think of its own TOS?</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>chatgtp think tos</td>\n",
       "      <td>[chatgtp, think, tos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>16671</td>\n",
       "      <td>j5mwpdr</td>\n",
       "      <td>t1_j5m6aj0</td>\n",
       "      <td>Don't know what they're referring to in the TO...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>know refer tos section seem noteworthy c c c k</td>\n",
       "      <td>[know, refer, tos, section, seem, noteworthy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52415</th>\n",
       "      <td>\u001a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "      <td>[nan]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49426 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 comment_id comment_parent_id  \\\n",
       "0              0    iztdxuh         t3_zj2aeu   \n",
       "1              1    iztn0q0         t3_zj2aeu   \n",
       "2              2    izudrph         t3_zj2aeu   \n",
       "3              3    iztfhtb         t3_zj2aeu   \n",
       "4              4    izu2as9         t3_zj2aeu   \n",
       "...          ...        ...               ...   \n",
       "52411      16668    j5m0v6m        t3_10jmvpj   \n",
       "52412      16669    j5m6aj0        t1_j5m0v6m   \n",
       "52413      16670    j5nylax        t1_j5m0v6m   \n",
       "52414      16671    j5mwpdr        t1_j5m6aj0   \n",
       "52415          \u001a        NaN               NaN   \n",
       "\n",
       "                                            comment_body     subreddit  \\\n",
       "0      I've been shocked for days now, I don't need c...     r/ChatGPT   \n",
       "1       \\n\\nI am so angry right now. I just wasted my...     r/ChatGPT   \n",
       "2      chatgpt karma whoring is here folks! just when...     r/ChatGPT   \n",
       "3                                     Worked on me, ngl.     r/ChatGPT   \n",
       "4      Certified 10/10, must-see moment. It really di...     r/ChatGPT   \n",
       "...                                                  ...           ...   \n",
       "52411             Read the T.O.S., you'll thank me later  r/technology   \n",
       "52412  What am I missing here... https://openai.com/t...  r/technology   \n",
       "52413            What does ChatGTP think of its own TOS?  r/technology   \n",
       "52414  Don't know what they're referring to in the TO...  r/technology   \n",
       "52415                                                NaN           NaN   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0                               shock day need clickbait   \n",
       "1      angry right waste time read post sub clickbait...   \n",
       "2      chatgpt karma whoring folk think stream though...   \n",
       "3                                               work ngl   \n",
       "4                   certify see moment really shock core   \n",
       "...                                                  ...   \n",
       "52411                                   read thank later   \n",
       "52412                                            missing   \n",
       "52413                                  chatgtp think tos   \n",
       "52414     know refer tos section seem noteworthy c c c k   \n",
       "52415                                                nan   \n",
       "\n",
       "                                            clean_tokens  \n",
       "0                          [shock, day, need, clickbait]  \n",
       "1      [angry, right, waste, time, read, post, sub, c...  \n",
       "2      [chatgpt, karma, whoring, folk, think, stream,...  \n",
       "3                                            [work, ngl]  \n",
       "4            [certify, see, moment, really, shock, core]  \n",
       "...                                                  ...  \n",
       "52411                               [read, thank, later]  \n",
       "52412                                          [missing]  \n",
       "52413                              [chatgtp, think, tos]  \n",
       "52414  [know, refer, tos, section, seem, noteworthy, ...  \n",
       "52415                                              [nan]  \n",
       "\n",
       "[49426 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = reddit_df.dropna(subset=[\"comment_body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>text_contain_academic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iztdxuh</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>i've been shocked for days now, i don't need c...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>shock day need clickbait</td>\n",
       "      <td>[shock, day, need, clickbait]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iztn0q0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>\\n\\ni am so angry right now. i just wasted my...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>[angry, right, waste, time, read, post, sub, c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>izudrph</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>chatgpt karma whoring folk think stream though...</td>\n",
       "      <td>[chatgpt, karma, whoring, folk, think, stream,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>iztfhtb</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>worked on me, ngl.</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>work ngl</td>\n",
       "      <td>[work, ngl]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>izu2as9</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>certified 10/10, must-see moment. it really di...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>certify see moment really shock core</td>\n",
       "      <td>[certify, see, moment, really, shock, core]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52410</th>\n",
       "      <td>16667</td>\n",
       "      <td>j4lbiix</td>\n",
       "      <td>t1_j4kgcac</td>\n",
       "      <td>scary thing is, in this future text wonâ€™t be t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>scary thing future text wont trustworthy case ...</td>\n",
       "      <td>[scary, thing, future, text, wont, trustworthy...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>16668</td>\n",
       "      <td>j5m0v6m</td>\n",
       "      <td>t3_10jmvpj</td>\n",
       "      <td>read the t.o.s., you'll thank me later</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>read thank later</td>\n",
       "      <td>[read, thank, later]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>16669</td>\n",
       "      <td>j5m6aj0</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>what am i missing here... https://openai.com/t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>missing</td>\n",
       "      <td>[missing]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>16670</td>\n",
       "      <td>j5nylax</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>what does chatgtp think of its own tos?</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>chatgtp think tos</td>\n",
       "      <td>[chatgtp, think, tos]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>16671</td>\n",
       "      <td>j5mwpdr</td>\n",
       "      <td>t1_j5m6aj0</td>\n",
       "      <td>don't know what they're referring to in the to...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>know refer tos section seem noteworthy c c c k</td>\n",
       "      <td>[know, refer, tos, section, seem, noteworthy, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49425 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 comment_id comment_parent_id  \\\n",
       "0              0    iztdxuh         t3_zj2aeu   \n",
       "1              1    iztn0q0         t3_zj2aeu   \n",
       "2              2    izudrph         t3_zj2aeu   \n",
       "3              3    iztfhtb         t3_zj2aeu   \n",
       "4              4    izu2as9         t3_zj2aeu   \n",
       "...          ...        ...               ...   \n",
       "52410      16667    j4lbiix        t1_j4kgcac   \n",
       "52411      16668    j5m0v6m        t3_10jmvpj   \n",
       "52412      16669    j5m6aj0        t1_j5m0v6m   \n",
       "52413      16670    j5nylax        t1_j5m0v6m   \n",
       "52414      16671    j5mwpdr        t1_j5m6aj0   \n",
       "\n",
       "                                            comment_body     subreddit  \\\n",
       "0      i've been shocked for days now, i don't need c...     r/ChatGPT   \n",
       "1       \\n\\ni am so angry right now. i just wasted my...     r/ChatGPT   \n",
       "2      chatgpt karma whoring is here folks! just when...     r/ChatGPT   \n",
       "3                                     worked on me, ngl.     r/ChatGPT   \n",
       "4      certified 10/10, must-see moment. it really di...     r/ChatGPT   \n",
       "...                                                  ...           ...   \n",
       "52410  scary thing is, in this future text wonâ€™t be t...  r/technology   \n",
       "52411             read the t.o.s., you'll thank me later  r/technology   \n",
       "52412  what am i missing here... https://openai.com/t...  r/technology   \n",
       "52413            what does chatgtp think of its own tos?  r/technology   \n",
       "52414  don't know what they're referring to in the to...  r/technology   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0                               shock day need clickbait   \n",
       "1      angry right waste time read post sub clickbait...   \n",
       "2      chatgpt karma whoring folk think stream though...   \n",
       "3                                               work ngl   \n",
       "4                   certify see moment really shock core   \n",
       "...                                                  ...   \n",
       "52410  scary thing future text wont trustworthy case ...   \n",
       "52411                                   read thank later   \n",
       "52412                                            missing   \n",
       "52413                                  chatgtp think tos   \n",
       "52414     know refer tos section seem noteworthy c c c k   \n",
       "\n",
       "                                            clean_tokens  \\\n",
       "0                          [shock, day, need, clickbait]   \n",
       "1      [angry, right, waste, time, read, post, sub, c...   \n",
       "2      [chatgpt, karma, whoring, folk, think, stream,...   \n",
       "3                                            [work, ngl]   \n",
       "4            [certify, see, moment, really, shock, core]   \n",
       "...                                                  ...   \n",
       "52410  [scary, thing, future, text, wont, trustworthy...   \n",
       "52411                               [read, thank, later]   \n",
       "52412                                          [missing]   \n",
       "52413                              [chatgtp, think, tos]   \n",
       "52414  [know, refer, tos, section, seem, noteworthy, ...   \n",
       "\n",
       "       text_contain_academic  \n",
       "0                      False  \n",
       "1                       True  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  \n",
       "...                      ...  \n",
       "52410                  False  \n",
       "52411                  False  \n",
       "52412                  False  \n",
       "52413                  False  \n",
       "52414                  False  \n",
       "\n",
       "[49425 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/p78_6rrn58d3q_81k3cgd9gw0000gn/T/ipykernel_25041/3301605234.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reddit_df[\"comment_body\"] = reddit_df[\"comment_body\"].str.lower()\n"
     ]
    }
   ],
   "source": [
    "reddit_df[\"comment_body\"] = reddit_df[\"comment_body\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iztdxuh</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>i've been shocked for days now, i don't need c...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>shock day need clickbait</td>\n",
       "      <td>[shock, day, need, clickbait]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iztn0q0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>\\n\\ni am so angry right now. i just wasted my...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>[angry, right, waste, time, read, post, sub, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>izudrph</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>chatgpt karma whoring folk think stream though...</td>\n",
       "      <td>[chatgpt, karma, whoring, folk, think, stream,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>iztfhtb</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>worked on me, ngl.</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>work ngl</td>\n",
       "      <td>[work, ngl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>izu2as9</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>certified 10/10, must-see moment. it really di...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>certify see moment really shock core</td>\n",
       "      <td>[certify, see, moment, really, shock, core]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52410</th>\n",
       "      <td>16667</td>\n",
       "      <td>j4lbiix</td>\n",
       "      <td>t1_j4kgcac</td>\n",
       "      <td>scary thing is, in this future text wonâ€™t be t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>scary thing future text wont trustworthy case ...</td>\n",
       "      <td>[scary, thing, future, text, wont, trustworthy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>16668</td>\n",
       "      <td>j5m0v6m</td>\n",
       "      <td>t3_10jmvpj</td>\n",
       "      <td>read the t.o.s., you'll thank me later</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>read thank later</td>\n",
       "      <td>[read, thank, later]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>16669</td>\n",
       "      <td>j5m6aj0</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>what am i missing here... https://openai.com/t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>missing</td>\n",
       "      <td>[missing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>16670</td>\n",
       "      <td>j5nylax</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>what does chatgtp think of its own tos?</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>chatgtp think tos</td>\n",
       "      <td>[chatgtp, think, tos]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>16671</td>\n",
       "      <td>j5mwpdr</td>\n",
       "      <td>t1_j5m6aj0</td>\n",
       "      <td>don't know what they're referring to in the to...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>know refer tos section seem noteworthy c c c k</td>\n",
       "      <td>[know, refer, tos, section, seem, noteworthy, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49425 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 comment_id comment_parent_id  \\\n",
       "0              0    iztdxuh         t3_zj2aeu   \n",
       "1              1    iztn0q0         t3_zj2aeu   \n",
       "2              2    izudrph         t3_zj2aeu   \n",
       "3              3    iztfhtb         t3_zj2aeu   \n",
       "4              4    izu2as9         t3_zj2aeu   \n",
       "...          ...        ...               ...   \n",
       "52410      16667    j4lbiix        t1_j4kgcac   \n",
       "52411      16668    j5m0v6m        t3_10jmvpj   \n",
       "52412      16669    j5m6aj0        t1_j5m0v6m   \n",
       "52413      16670    j5nylax        t1_j5m0v6m   \n",
       "52414      16671    j5mwpdr        t1_j5m6aj0   \n",
       "\n",
       "                                            comment_body     subreddit  \\\n",
       "0      i've been shocked for days now, i don't need c...     r/ChatGPT   \n",
       "1       \\n\\ni am so angry right now. i just wasted my...     r/ChatGPT   \n",
       "2      chatgpt karma whoring is here folks! just when...     r/ChatGPT   \n",
       "3                                     worked on me, ngl.     r/ChatGPT   \n",
       "4      certified 10/10, must-see moment. it really di...     r/ChatGPT   \n",
       "...                                                  ...           ...   \n",
       "52410  scary thing is, in this future text wonâ€™t be t...  r/technology   \n",
       "52411             read the t.o.s., you'll thank me later  r/technology   \n",
       "52412  what am i missing here... https://openai.com/t...  r/technology   \n",
       "52413            what does chatgtp think of its own tos?  r/technology   \n",
       "52414  don't know what they're referring to in the to...  r/technology   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0                               shock day need clickbait   \n",
       "1      angry right waste time read post sub clickbait...   \n",
       "2      chatgpt karma whoring folk think stream though...   \n",
       "3                                               work ngl   \n",
       "4                   certify see moment really shock core   \n",
       "...                                                  ...   \n",
       "52410  scary thing future text wont trustworthy case ...   \n",
       "52411                                   read thank later   \n",
       "52412                                            missing   \n",
       "52413                                  chatgtp think tos   \n",
       "52414     know refer tos section seem noteworthy c c c k   \n",
       "\n",
       "                                            clean_tokens  \n",
       "0                          [shock, day, need, clickbait]  \n",
       "1      [angry, right, waste, time, read, post, sub, c...  \n",
       "2      [chatgpt, karma, whoring, folk, think, stream,...  \n",
       "3                                            [work, ngl]  \n",
       "4            [certify, see, moment, really, shock, core]  \n",
       "...                                                  ...  \n",
       "52410  [scary, thing, future, text, wont, trustworthy...  \n",
       "52411                               [read, thank, later]  \n",
       "52412                                          [missing]  \n",
       "52413                              [chatgtp, think, tos]  \n",
       "52414  [know, refer, tos, section, seem, noteworthy, ...  \n",
       "\n",
       "[49425 rows x 7 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "academic_words_list_pattern = '|'.join(academic_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class|lecture|professor|prof|homework|hw|exam|examinations|assignment|study|degree|gpa|cap|scholarship|scholar|research|thesis|lab|campus|graduation|grad|syllabus|textbook|textbooks|student|students|academic|acad|acads|registrar|tuition|coursework|course|attendance|faculty|teacher|teach|learn|internship|intern|library|peer|peers|school|schools|university|uni|college|colleges'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "academic_words_list_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/52/p78_6rrn58d3q_81k3cgd9gw0000gn/T/ipykernel_25041/1998606852.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  reddit_df[\"text_contain_academic\"] = reddit_df[\"comment_body\"].str.contains(academic_words_list_pattern)\n"
     ]
    }
   ],
   "source": [
    "reddit_df[\"text_contain_academic\"] = reddit_df[\"comment_body\"].str.contains(academic_words_list_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>text_contain_academic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>iztdxuh</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>i've been shocked for days now, i don't need c...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>shock day need clickbait</td>\n",
       "      <td>[shock, day, need, clickbait]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iztn0q0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>\\n\\ni am so angry right now. i just wasted my...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>[angry, right, waste, time, read, post, sub, c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>izudrph</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>chatgpt karma whoring is here folks! just when...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>chatgpt karma whoring folk think stream though...</td>\n",
       "      <td>[chatgpt, karma, whoring, folk, think, stream,...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>iztfhtb</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>worked on me, ngl.</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>work ngl</td>\n",
       "      <td>[work, ngl]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>izu2as9</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>certified 10/10, must-see moment. it really di...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>certify see moment really shock core</td>\n",
       "      <td>[certify, see, moment, really, shock, core]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52410</th>\n",
       "      <td>16667</td>\n",
       "      <td>j4lbiix</td>\n",
       "      <td>t1_j4kgcac</td>\n",
       "      <td>scary thing is, in this future text wonâ€™t be t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>scary thing future text wont trustworthy case ...</td>\n",
       "      <td>[scary, thing, future, text, wont, trustworthy...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52411</th>\n",
       "      <td>16668</td>\n",
       "      <td>j5m0v6m</td>\n",
       "      <td>t3_10jmvpj</td>\n",
       "      <td>read the t.o.s., you'll thank me later</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>read thank later</td>\n",
       "      <td>[read, thank, later]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52412</th>\n",
       "      <td>16669</td>\n",
       "      <td>j5m6aj0</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>what am i missing here... https://openai.com/t...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>missing</td>\n",
       "      <td>[missing]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52413</th>\n",
       "      <td>16670</td>\n",
       "      <td>j5nylax</td>\n",
       "      <td>t1_j5m0v6m</td>\n",
       "      <td>what does chatgtp think of its own tos?</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>chatgtp think tos</td>\n",
       "      <td>[chatgtp, think, tos]</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52414</th>\n",
       "      <td>16671</td>\n",
       "      <td>j5mwpdr</td>\n",
       "      <td>t1_j5m6aj0</td>\n",
       "      <td>don't know what they're referring to in the to...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>know refer tos section seem noteworthy c c c k</td>\n",
       "      <td>[know, refer, tos, section, seem, noteworthy, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49425 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 comment_id comment_parent_id  \\\n",
       "0              0    iztdxuh         t3_zj2aeu   \n",
       "1              1    iztn0q0         t3_zj2aeu   \n",
       "2              2    izudrph         t3_zj2aeu   \n",
       "3              3    iztfhtb         t3_zj2aeu   \n",
       "4              4    izu2as9         t3_zj2aeu   \n",
       "...          ...        ...               ...   \n",
       "52410      16667    j4lbiix        t1_j4kgcac   \n",
       "52411      16668    j5m0v6m        t3_10jmvpj   \n",
       "52412      16669    j5m6aj0        t1_j5m0v6m   \n",
       "52413      16670    j5nylax        t1_j5m0v6m   \n",
       "52414      16671    j5mwpdr        t1_j5m6aj0   \n",
       "\n",
       "                                            comment_body     subreddit  \\\n",
       "0      i've been shocked for days now, i don't need c...     r/ChatGPT   \n",
       "1       \\n\\ni am so angry right now. i just wasted my...     r/ChatGPT   \n",
       "2      chatgpt karma whoring is here folks! just when...     r/ChatGPT   \n",
       "3                                     worked on me, ngl.     r/ChatGPT   \n",
       "4      certified 10/10, must-see moment. it really di...     r/ChatGPT   \n",
       "...                                                  ...           ...   \n",
       "52410  scary thing is, in this future text wonâ€™t be t...  r/technology   \n",
       "52411             read the t.o.s., you'll thank me later  r/technology   \n",
       "52412  what am i missing here... https://openai.com/t...  r/technology   \n",
       "52413            what does chatgtp think of its own tos?  r/technology   \n",
       "52414  don't know what they're referring to in the to...  r/technology   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0                               shock day need clickbait   \n",
       "1      angry right waste time read post sub clickbait...   \n",
       "2      chatgpt karma whoring folk think stream though...   \n",
       "3                                               work ngl   \n",
       "4                   certify see moment really shock core   \n",
       "...                                                  ...   \n",
       "52410  scary thing future text wont trustworthy case ...   \n",
       "52411                                   read thank later   \n",
       "52412                                            missing   \n",
       "52413                                  chatgtp think tos   \n",
       "52414     know refer tos section seem noteworthy c c c k   \n",
       "\n",
       "                                            clean_tokens  \\\n",
       "0                          [shock, day, need, clickbait]   \n",
       "1      [angry, right, waste, time, read, post, sub, c...   \n",
       "2      [chatgpt, karma, whoring, folk, think, stream,...   \n",
       "3                                            [work, ngl]   \n",
       "4            [certify, see, moment, really, shock, core]   \n",
       "...                                                  ...   \n",
       "52410  [scary, thing, future, text, wont, trustworthy...   \n",
       "52411                               [read, thank, later]   \n",
       "52412                                          [missing]   \n",
       "52413                              [chatgtp, think, tos]   \n",
       "52414  [know, refer, tos, section, seem, noteworthy, ...   \n",
       "\n",
       "       text_contain_academic  \n",
       "0                      False  \n",
       "1                       True  \n",
       "2                      False  \n",
       "3                      False  \n",
       "4                      False  \n",
       "...                      ...  \n",
       "52410                  False  \n",
       "52411                  False  \n",
       "52412                  False  \n",
       "52413                  False  \n",
       "52414                  False  \n",
       "\n",
       "[49425 rows x 8 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    36511\n",
       "True     12914\n",
       "Name: text_contain_academic, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_df[\"text_contain_academic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acad_df = reddit_df[reddit_df[\"text_contain_academic\"] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_parent_id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "      <th>text_contain_academic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iztn0q0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>\\n\\ni am so angry right now. i just wasted my...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>[angry, right, waste, time, read, post, sub, c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>izwlu83</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>i asked to do the opposite of that:\\n\\n\"a titl...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>ask opposite title likely generate upvotes gar...</td>\n",
       "      <td>[ask, opposite, title, likely, generate, upvot...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>j0bxgq0</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>i was messing around and got it to create this...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>mess around get create masterpiecelo behold mo...</td>\n",
       "      <td>[mess, around, get, create, masterpiecelo, beh...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>j0c5wsj</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>dead internet theory just with more steps</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>dead internet theory step</td>\n",
       "      <td>[dead, internet, theory, step]</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>j18jqxa</td>\n",
       "      <td>t3_zj2aeu</td>\n",
       "      <td>a bunch of stuff iâ€™ve found. \\n\\ncgpt can draw...</td>\n",
       "      <td>r/ChatGPT</td>\n",
       "      <td>bunch stuff ive find cgpt draw shape follow di...</td>\n",
       "      <td>[bunch, stuff, ive, find, cgpt, draw, shape, f...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52398</th>\n",
       "      <td>16655</td>\n",
       "      <td>j4jd7lt</td>\n",
       "      <td>t1_j4j72zf</td>\n",
       "      <td>just wanted to point out that if you lost your...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>want point lose job career option pursue easy ...</td>\n",
       "      <td>[want, point, lose, job, career, option, pursu...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52400</th>\n",
       "      <td>16657</td>\n",
       "      <td>j4j9fzg</td>\n",
       "      <td>t1_j4j6qvu</td>\n",
       "      <td>yeah deepfakes, ai-assisted propaganda and god...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>yeah deepfakes ai assist propaganda god know e...</td>\n",
       "      <td>[yeah, deepfakes, ai, assist, propaganda, god,...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>16659</td>\n",
       "      <td>j4jed9j</td>\n",
       "      <td>t1_j4jbhm0</td>\n",
       "      <td>well, at least for the moment my job is not in...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>well least moment job jeopardy say understand ...</td>\n",
       "      <td>[well, least, moment, job, jeopardy, say, unde...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52408</th>\n",
       "      <td>16665</td>\n",
       "      <td>j4kn8zu</td>\n",
       "      <td>t1_j4kk704</td>\n",
       "      <td>that's not what i said at all.\\n\\nin fact, i'm...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>say fact get lot downvotes literally say multi...</td>\n",
       "      <td>[say, fact, get, lot, downvotes, literally, sa...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52409</th>\n",
       "      <td>16666</td>\n",
       "      <td>j4l41sl</td>\n",
       "      <td>t1_j4kgcac</td>\n",
       "      <td>re wikipedia, although students have getting h...</td>\n",
       "      <td>r/technology</td>\n",
       "      <td>student get hammer message forever still go so...</td>\n",
       "      <td>[student, get, hammer, message, forever, still...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12914 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 comment_id comment_parent_id  \\\n",
       "1              1    iztn0q0         t3_zj2aeu   \n",
       "11            11    izwlu83         t3_zj2aeu   \n",
       "23            23    j0bxgq0         t3_zj2aeu   \n",
       "50            50    j0c5wsj         t3_zj2aeu   \n",
       "68            68    j18jqxa         t3_zj2aeu   \n",
       "...          ...        ...               ...   \n",
       "52398      16655    j4jd7lt        t1_j4j72zf   \n",
       "52400      16657    j4j9fzg        t1_j4j6qvu   \n",
       "52402      16659    j4jed9j        t1_j4jbhm0   \n",
       "52408      16665    j4kn8zu        t1_j4kk704   \n",
       "52409      16666    j4l41sl        t1_j4kgcac   \n",
       "\n",
       "                                            comment_body     subreddit  \\\n",
       "1       \\n\\ni am so angry right now. i just wasted my...     r/ChatGPT   \n",
       "11     i asked to do the opposite of that:\\n\\n\"a titl...     r/ChatGPT   \n",
       "23     i was messing around and got it to create this...     r/ChatGPT   \n",
       "50             dead internet theory just with more steps     r/ChatGPT   \n",
       "68     a bunch of stuff iâ€™ve found. \\n\\ncgpt can draw...     r/ChatGPT   \n",
       "...                                                  ...           ...   \n",
       "52398  just wanted to point out that if you lost your...  r/technology   \n",
       "52400  yeah deepfakes, ai-assisted propaganda and god...  r/technology   \n",
       "52402  well, at least for the moment my job is not in...  r/technology   \n",
       "52408  that's not what i said at all.\\n\\nin fact, i'm...  r/technology   \n",
       "52409  re wikipedia, although students have getting h...  r/technology   \n",
       "\n",
       "                                              clean_text  \\\n",
       "1      angry right waste time read post sub clickbait...   \n",
       "11     ask opposite title likely generate upvotes gar...   \n",
       "23     mess around get create masterpiecelo behold mo...   \n",
       "50                             dead internet theory step   \n",
       "68     bunch stuff ive find cgpt draw shape follow di...   \n",
       "...                                                  ...   \n",
       "52398  want point lose job career option pursue easy ...   \n",
       "52400  yeah deepfakes ai assist propaganda god know e...   \n",
       "52402  well least moment job jeopardy say understand ...   \n",
       "52408  say fact get lot downvotes literally say multi...   \n",
       "52409  student get hammer message forever still go so...   \n",
       "\n",
       "                                            clean_tokens  \\\n",
       "1      [angry, right, waste, time, read, post, sub, c...   \n",
       "11     [ask, opposite, title, likely, generate, upvot...   \n",
       "23     [mess, around, get, create, masterpiecelo, beh...   \n",
       "50                        [dead, internet, theory, step]   \n",
       "68     [bunch, stuff, ive, find, cgpt, draw, shape, f...   \n",
       "...                                                  ...   \n",
       "52398  [want, point, lose, job, career, option, pursu...   \n",
       "52400  [yeah, deepfakes, ai, assist, propaganda, god,...   \n",
       "52402  [well, least, moment, job, jeopardy, say, unde...   \n",
       "52408  [say, fact, get, lot, downvotes, literally, sa...   \n",
       "52409  [student, get, hammer, message, forever, still...   \n",
       "\n",
       "       text_contain_academic  \n",
       "1                       True  \n",
       "11                      True  \n",
       "23                      True  \n",
       "50                      True  \n",
       "68                      True  \n",
       "...                      ...  \n",
       "52398                   True  \n",
       "52400                   True  \n",
       "52402                   True  \n",
       "52408                   True  \n",
       "52409                   True  \n",
       "\n",
       "[12914 rows x 8 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_acad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acad_df = reddit_acad_df.drop(columns=['Unnamed: 0',\t\"comment_id\",\t\"comment_parent_id\", \"subreddit\",\t\"text_contain_academic\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_body</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\ni am so angry right now. i just wasted my...</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>[angry, right, waste, time, read, post, sub, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>i asked to do the opposite of that:\\n\\n\"a titl...</td>\n",
       "      <td>ask opposite title likely generate upvotes gar...</td>\n",
       "      <td>[ask, opposite, title, likely, generate, upvot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>i was messing around and got it to create this...</td>\n",
       "      <td>mess around get create masterpiecelo behold mo...</td>\n",
       "      <td>[mess, around, get, create, masterpiecelo, beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>dead internet theory just with more steps</td>\n",
       "      <td>dead internet theory step</td>\n",
       "      <td>[dead, internet, theory, step]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>a bunch of stuff iâ€™ve found. \\n\\ncgpt can draw...</td>\n",
       "      <td>bunch stuff ive find cgpt draw shape follow di...</td>\n",
       "      <td>[bunch, stuff, ive, find, cgpt, draw, shape, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52398</th>\n",
       "      <td>just wanted to point out that if you lost your...</td>\n",
       "      <td>want point lose job career option pursue easy ...</td>\n",
       "      <td>[want, point, lose, job, career, option, pursu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52400</th>\n",
       "      <td>yeah deepfakes, ai-assisted propaganda and god...</td>\n",
       "      <td>yeah deepfakes ai assist propaganda god know e...</td>\n",
       "      <td>[yeah, deepfakes, ai, assist, propaganda, god,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>well, at least for the moment my job is not in...</td>\n",
       "      <td>well least moment job jeopardy say understand ...</td>\n",
       "      <td>[well, least, moment, job, jeopardy, say, unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52408</th>\n",
       "      <td>that's not what i said at all.\\n\\nin fact, i'm...</td>\n",
       "      <td>say fact get lot downvotes literally say multi...</td>\n",
       "      <td>[say, fact, get, lot, downvotes, literally, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52409</th>\n",
       "      <td>re wikipedia, although students have getting h...</td>\n",
       "      <td>student get hammer message forever still go so...</td>\n",
       "      <td>[student, get, hammer, message, forever, still...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12914 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_body  \\\n",
       "1       \\n\\ni am so angry right now. i just wasted my...   \n",
       "11     i asked to do the opposite of that:\\n\\n\"a titl...   \n",
       "23     i was messing around and got it to create this...   \n",
       "50             dead internet theory just with more steps   \n",
       "68     a bunch of stuff iâ€™ve found. \\n\\ncgpt can draw...   \n",
       "...                                                  ...   \n",
       "52398  just wanted to point out that if you lost your...   \n",
       "52400  yeah deepfakes, ai-assisted propaganda and god...   \n",
       "52402  well, at least for the moment my job is not in...   \n",
       "52408  that's not what i said at all.\\n\\nin fact, i'm...   \n",
       "52409  re wikipedia, although students have getting h...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "1      angry right waste time read post sub clickbait...   \n",
       "11     ask opposite title likely generate upvotes gar...   \n",
       "23     mess around get create masterpiecelo behold mo...   \n",
       "50                             dead internet theory step   \n",
       "68     bunch stuff ive find cgpt draw shape follow di...   \n",
       "...                                                  ...   \n",
       "52398  want point lose job career option pursue easy ...   \n",
       "52400  yeah deepfakes ai assist propaganda god know e...   \n",
       "52402  well least moment job jeopardy say understand ...   \n",
       "52408  say fact get lot downvotes literally say multi...   \n",
       "52409  student get hammer message forever still go so...   \n",
       "\n",
       "                                            clean_tokens  \n",
       "1      [angry, right, waste, time, read, post, sub, c...  \n",
       "11     [ask, opposite, title, likely, generate, upvot...  \n",
       "23     [mess, around, get, create, masterpiecelo, beh...  \n",
       "50                        [dead, internet, theory, step]  \n",
       "68     [bunch, stuff, ive, find, cgpt, draw, shape, f...  \n",
       "...                                                  ...  \n",
       "52398  [want, point, lose, job, career, option, pursu...  \n",
       "52400  [yeah, deepfakes, ai, assist, propaganda, god,...  \n",
       "52402  [well, least, moment, job, jeopardy, say, unde...  \n",
       "52408  [say, fact, get, lot, downvotes, literally, sa...  \n",
       "52409  [student, get, hammer, message, forever, still...  \n",
       "\n",
       "[12914 rows x 3 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_acad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acad_df = reddit_acad_df.replace('\\n',' ', regex=True)\n",
    "reddit_acad_df = reddit_acad_df.apply(lambda x: x.str.replace(',',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acad_df = reddit_acad_df.reset_index(drop=True)\n",
    "reddit_acad_df.index.names = ['id']\n",
    "reddit_acad_df = reddit_acad_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i am so angry right now. i just wasted my t...</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i asked to do the opposite of that:  \"a title ...</td>\n",
       "      <td>ask opposite title likely generate upvotes gar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i was messing around and got it to create this...</td>\n",
       "      <td>mess around get create masterpiecelo behold mo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dead internet theory just with more steps</td>\n",
       "      <td>dead internet theory step</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a bunch of stuff iâ€™ve found.   cgpt can draw s...</td>\n",
       "      <td>bunch stuff ive find cgpt draw shape follow di...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12909</th>\n",
       "      <td>12909</td>\n",
       "      <td>just wanted to point out that if you lost your...</td>\n",
       "      <td>want point lose job career option pursue easy ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12910</th>\n",
       "      <td>12910</td>\n",
       "      <td>yeah deepfakes  ai-assisted propaganda and god...</td>\n",
       "      <td>yeah deepfakes ai assist propaganda god know e...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12911</th>\n",
       "      <td>12911</td>\n",
       "      <td>well  at least for the moment my job is not in...</td>\n",
       "      <td>well least moment job jeopardy say understand ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12912</th>\n",
       "      <td>12912</td>\n",
       "      <td>that's not what i said at all.  in fact  i'm g...</td>\n",
       "      <td>say fact get lot downvotes literally say multi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12913</th>\n",
       "      <td>12913</td>\n",
       "      <td>re wikipedia  although students have getting h...</td>\n",
       "      <td>student get hammer message forever still go so...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12914 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                       comment_body  \\\n",
       "0          0     i am so angry right now. i just wasted my t...   \n",
       "1          1  i asked to do the opposite of that:  \"a title ...   \n",
       "2          2  i was messing around and got it to create this...   \n",
       "3          3          dead internet theory just with more steps   \n",
       "4          4  a bunch of stuff iâ€™ve found.   cgpt can draw s...   \n",
       "...      ...                                                ...   \n",
       "12909  12909  just wanted to point out that if you lost your...   \n",
       "12910  12910  yeah deepfakes  ai-assisted propaganda and god...   \n",
       "12911  12911  well  at least for the moment my job is not in...   \n",
       "12912  12912  that's not what i said at all.  in fact  i'm g...   \n",
       "12913  12913  re wikipedia  although students have getting h...   \n",
       "\n",
       "                                              clean_text  clean_tokens  \n",
       "0      angry right waste time read post sub clickbait...           NaN  \n",
       "1      ask opposite title likely generate upvotes gar...           NaN  \n",
       "2      mess around get create masterpiecelo behold mo...           NaN  \n",
       "3                              dead internet theory step           NaN  \n",
       "4      bunch stuff ive find cgpt draw shape follow di...           NaN  \n",
       "...                                                  ...           ...  \n",
       "12909  want point lose job career option pursue easy ...           NaN  \n",
       "12910  yeah deepfakes ai assist propaganda god know e...           NaN  \n",
       "12911  well least moment job jeopardy say understand ...           NaN  \n",
       "12912  say fact get lot downvotes literally say multi...           NaN  \n",
       "12913  student get hammer message forever still go so...           NaN  \n",
       "\n",
       "[12914 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_acad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acad_df = reddit_acad_df.drop(columns=[\"clean_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>i am so angry right now. i just wasted my t...</td>\n",
       "      <td>angry right waste time read post sub clickbait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>i asked to do the opposite of that:  \"a title ...</td>\n",
       "      <td>ask opposite title likely generate upvotes gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>i was messing around and got it to create this...</td>\n",
       "      <td>mess around get create masterpiecelo behold mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>dead internet theory just with more steps</td>\n",
       "      <td>dead internet theory step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>a bunch of stuff iâ€™ve found.   cgpt can draw s...</td>\n",
       "      <td>bunch stuff ive find cgpt draw shape follow di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12909</th>\n",
       "      <td>12909</td>\n",
       "      <td>just wanted to point out that if you lost your...</td>\n",
       "      <td>want point lose job career option pursue easy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12910</th>\n",
       "      <td>12910</td>\n",
       "      <td>yeah deepfakes  ai-assisted propaganda and god...</td>\n",
       "      <td>yeah deepfakes ai assist propaganda god know e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12911</th>\n",
       "      <td>12911</td>\n",
       "      <td>well  at least for the moment my job is not in...</td>\n",
       "      <td>well least moment job jeopardy say understand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12912</th>\n",
       "      <td>12912</td>\n",
       "      <td>that's not what i said at all.  in fact  i'm g...</td>\n",
       "      <td>say fact get lot downvotes literally say multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12913</th>\n",
       "      <td>12913</td>\n",
       "      <td>re wikipedia  although students have getting h...</td>\n",
       "      <td>student get hammer message forever still go so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12914 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                       comment_body  \\\n",
       "0          0     i am so angry right now. i just wasted my t...   \n",
       "1          1  i asked to do the opposite of that:  \"a title ...   \n",
       "2          2  i was messing around and got it to create this...   \n",
       "3          3          dead internet theory just with more steps   \n",
       "4          4  a bunch of stuff iâ€™ve found.   cgpt can draw s...   \n",
       "...      ...                                                ...   \n",
       "12909  12909  just wanted to point out that if you lost your...   \n",
       "12910  12910  yeah deepfakes  ai-assisted propaganda and god...   \n",
       "12911  12911  well  at least for the moment my job is not in...   \n",
       "12912  12912  that's not what i said at all.  in fact  i'm g...   \n",
       "12913  12913  re wikipedia  although students have getting h...   \n",
       "\n",
       "                                              clean_text  \n",
       "0      angry right waste time read post sub clickbait...  \n",
       "1      ask opposite title likely generate upvotes gar...  \n",
       "2      mess around get create masterpiecelo behold mo...  \n",
       "3                              dead internet theory step  \n",
       "4      bunch stuff ive find cgpt draw shape follow di...  \n",
       "...                                                  ...  \n",
       "12909  want point lose job career option pursue easy ...  \n",
       "12910  yeah deepfakes ai assist propaganda god know e...  \n",
       "12911  well least moment job jeopardy say understand ...  \n",
       "12912  say fact get lot downvotes literally say multi...  \n",
       "12913  student get hammer message forever still go so...  \n",
       "\n",
       "[12914 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_acad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_acad_df.to_csv(\"../cleaned_reddit.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
